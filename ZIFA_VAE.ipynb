{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZIFA_VAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm8XUQfsB5Fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tfd = tf.contrib.distributions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb7IQ1QuGGYA",
        "colab_type": "text"
      },
      "source": [
        "Importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAeDMui4GFex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = \"gene_expression.txt\"\n",
        "\n",
        "expression=np.loadtxt(data_path )# observed data\n",
        "#labels\n",
        "label = np.loadtxt(\"labels.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izdk4X9GB7Rm",
        "colab_type": "code",
        "outputId": "64842e90-1c81-4d9d-b1fb-ffa3315566cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "\n",
        "n_y=558   #dim of observed data\n",
        "n_z=10   #dim of z\n",
        "learn_rate=0.0001\n",
        "logW= tf.Variable(np.random.normal(size=n_y))# log of W\n",
        "loglambda=tf.Variable(np.random.normal(size=1))#log of lambda\n",
        "print(logW.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(558,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWI51HdCzNNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(X, batch_size = 100): # get batches of traing data\n",
        "    \n",
        "\t\n",
        "    n_batches =len(X)//batch_size\n",
        "    X = X[:n_batches*batch_size]\n",
        "\n",
        "\t# Loop over batches and yield\n",
        "    for b in range(0, len(X), batch_size):\n",
        "        yield X[b:b+batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLPbIVlOCM_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encorder\n",
        "def encoder(x):\n",
        "    mu = tf.layers.dense(x, n_z)\n",
        "    logsigma = tf.layers.dense(x, n_z)\n",
        "    return mu, logsigma\n",
        "\n",
        "\n",
        "#decoder\n",
        "def decoder(z):\n",
        "    f_z=tf.layers.dense(z, n_y)\n",
        "    return f_z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4Ko5FIzCSQt",
        "colab_type": "code",
        "outputId": "5ac2bcc3-515f-40b2-af88-d91604662c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data= tf.placeholder(tf.float32, [None, n_y], name = 'y')\n",
        "\n",
        "#z posterior sampling\n",
        "def sampling_z( mu, logsigma):\n",
        "    std = tf.exp(0.5*logsigma)\n",
        "    eps = tf.random_normal(shape=[tf.shape(data)[0],\n",
        "                              n_z],\n",
        "                       mean=0.0,\n",
        "                       stddev=1.0)\n",
        "    return mu + tf.sqrt(std) * eps\n",
        "# posterior of z given y\n",
        "z_mu, z_logsigma = encoder(data)\n",
        "print(z_logsigma.shape)\n",
        "z = sampling_z(z_mu, z_logsigma)\n",
        "print(z)\n",
        "x_tilde = decoder(z)\n",
        "W = tf.exp(logW)\n",
        "lam_bda=tf.exp(loglambda)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 10)\n",
            "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM1CXFG3GPWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W=tf.cast(W,tf.float32)\n",
        "lam_bda=tf.cast(lam_bda,tf.float32)\n",
        "er=1e-8\n",
        "l_zero =  -tf.log(1+2*W*lam_bda)/2 - x_tilde*x_tilde*lam_bda/(1+2*W*lam_bda)\n",
        "print(l_zero.shape)\n",
        "l_nonzero=tf.log(1-tf.exp(-lam_bda*data*data)+er)  - tf.log(W+er)/2 - (data-x_tilde)*(data-x_tilde)/(2*W)\n",
        "l=tf.multiply(tf.cast(data<er,tf.float32),l_zero)+tf.multiply(tf.cast(data>=er,tf.float32),l_nonzero)\n",
        "Y = tf.distributions.Normal(tf.zeros_like(z_mu), tf.ones_like(z_logsigma))\n",
        "X = tf.distributions.Normal(z_mu, tf.sqrt(tf.exp(z_logsigma)))\n",
        "     \n",
        "kl_z =tf.distributions.kl_divergence(X, Y)\n",
        "print(kl_z)     \n",
        "lossv = - tf.reduce_sum(l,1) +tf.reduce_sum(kl_z,1) \n",
        "loss=(tf.reduce_mean(lossv))\n",
        "train_op = tf.train.AdamOptimizer(learn_rate).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOrOQFyrHfSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "sess=tf.Session()\n",
        "iteration=1\n",
        "sess.run(tf.global_variables_initializer())\n",
        "los_old=0\n",
        "for i in range(800):\n",
        "   for X in get_batches(expression, 100):#batch_size=100\n",
        "           \n",
        "                sess.run(train_op,{data: X})\n",
        "                iteration=iteration+1\n",
        "    \n",
        "            \n",
        "            # Print at each 5 iters\n",
        "                if (iteration % 10 == 0):\n",
        "                  los=sess.run(loss,{data: expression})\n",
        "                  print(los)\n",
        "                \n",
        "                  if abs(los-los_old)<0.05:\n",
        "                    break\n",
        "                  los_old=los\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzk3Wsre_mk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z=sess.run(z,{data: expression})\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_GJJ9Bc_5LH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "25af0c0a-22ef-4fb7-c17d-2fc60ee661d6"
      },
      "source": [
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
        "from sklearn.metrics import adjusted_rand_score as ARI\n",
        "\n",
        "labels_pred_Z = KMeans(7, n_jobs=8, n_init=100).fit_predict(Z)\n",
        "print(\"Tthe NMI and ARI is\")\n",
        "[NMI(label, labels_pred_Z), ARI(label, labels_pred_Z)]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tthe NMI and ARI is\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7540025500601544, 0.7114940572618722]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVdRaVMoS3ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGnD5yEaAJMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}