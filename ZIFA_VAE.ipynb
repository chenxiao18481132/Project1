{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZIFA_VAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IE8u-M0JOPg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Intigrate over x\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "& \\int p_{i j}\\left(x_{i j}\\right) \\mathcal{N}\\left(x_{i j} ; \\tilde{\\mu}_{i j}\\left(z_{i}\\right), w_{j}^{2}\\right) d x_{i j} \\\\\n",
        "=& \\int \\exp \\left(-\\lambda x_{i j}^{2}\\right) \\frac{1}{\\sqrt{2 \\pi} w_{j}} \\exp \\left(-\\frac{\\left(x_{i j}-\\tilde{\\mu}_{i j}\\right)^{2}}{2 w_{j}^{2}}\\right) d x_{i j} \\\\\n",
        "=&\\frac{1}{\\sqrt{1+2 \\lambda w_{j}^{2}}} \\exp \\left(-\\frac{\\lambda\\tilde{\\mu}_{i j}^{2} }{1+2\\lambda w_{j}^{2} }\\right)\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "The conditional distribution of $y$ is\n",
        "\\begin{equation}\n",
        "\\begin{aligned} \\log p\\left(\\mathbf{y}_{i} | \\mathbf{z}_{i}\\right)=& \\sum_{j : y_{i j}=0} \\log \\left[\\frac{1}{\\sqrt{1+2\\lambda w_{j}^{2} }} \\exp \\left(-\\frac{ \\lambda \\tilde{\\mu}_{i j}^{2}}{1+2 \\lambda w_{j}^{2} }\\right)\\right] \\\\ &+\\sum_{j : y_{i j} \\neq 0} \\log \\left[\\left(1-\\exp \\left(-\\lambda y_{i j}^{2}\\right)\\right) \\frac{1}{\\sqrt{2 \\pi} w_{j}} \\exp \\left(-\\frac{\\left(y_{i j}-\\tilde{\\mu}_{i j}\\right)^{2}}{2 w_{j}^{2}}\\right)\\right] .\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "Our target is to get $p(z_i|y_i)$ \\\\\n",
        "\n",
        "\n",
        "So we can use VAE \n",
        "\n",
        "Encoder:\n",
        "\\begin{equation}\n",
        "\\begin{aligned} \\boldsymbol{\\mu}_{i}, \\boldsymbol{\\sigma}_{i}^{2} &=f_{\\phi}\\left(\\mathbf{y}_{i}\\right) \\\\ q_{\\phi}\\left(\\mathbf{z}_{i} | \\mathbf{y}_{i}\\right) &=\\mathcal{N}\\left(\\boldsymbol{\\mu}_{i}, \\boldsymbol{\\sigma}_{i}^{2}\\right) \\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "Decoeder:\n",
        "\\begin{equation}\n",
        "p\\left(\\mathbf{z}_{i}\\right)=\\mathcal{N}(\\mathbf{0}, \\mathbf{I})\n",
        "\\end{equation}\n",
        "\\begin{equation}\n",
        "\\tilde{\\mathbf{x}}_{i}=f_{\\theta}\\left(\\mathbf{z}_{i}\\right)\n",
        "\\end{equation}\n",
        "The evidence lower  bound (ELBO):\n",
        "\\begin{equation}\n",
        "elbo=\\mathbb{E}_{q_{\\phi}\\left(\\mathbf{z}_{i} | \\mathbf{y}_{i}\\right)}\\left[\\log p_{\\boldsymbol{\\theta},\\mathbf{w},\\boldsymbol{\\lambda}}\\left(\\mathbf{y}_{i} | \\mathbf{z}_{i}\\right)\\right]-D_{K L}\\left(q_{\\phi}\\left(\\mathbf{z}_{i} | \\mathbf{y}_{i}\\right) \\| p\\left(\\mathbf{z}_{i}\\right)\\right)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm8XUQfsB5Fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tfd = tf.contrib.distributions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb7IQ1QuGGYA",
        "colab_type": "text"
      },
      "source": [
        "Importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAeDMui4GFex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = \"gene_expression.txt\"\n",
        "\n",
        "expression=np.loadtxt(data_path )# observed data\n",
        "#labels\n",
        "label = np.loadtxt(\"labels.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izdk4X9GB7Rm",
        "colab_type": "code",
        "outputId": "64842e90-1c81-4d9d-b1fb-ffa3315566cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "\n",
        "n_y=558   #dim of observed data\n",
        "n_z=10   #dim of z\n",
        "learn_rate=0.0001\n",
        "logW= tf.Variable(np.random.normal(size=n_y))# log of W\n",
        "loglambda=tf.Variable(np.random.normal(size=1))#log of lambda\n",
        "print(logW.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(558,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWI51HdCzNNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(X, batch_size = 100): # get batches of traing data\n",
        "    \n",
        "\t\n",
        "    n_batches =len(X)//batch_size\n",
        "    X = X[:n_batches*batch_size]\n",
        "\n",
        "\t# Loop over batches and yield\n",
        "    for b in range(0, len(X), batch_size):\n",
        "        yield X[b:b+batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLPbIVlOCM_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encorder\n",
        "def encoder(x):\n",
        "    mu = tf.layers.dense(x, n_z)\n",
        "    logsigma = tf.layers.dense(x, n_z)\n",
        "    return mu, logsigma\n",
        "\n",
        "\n",
        "#decoder\n",
        "def decoder(z):\n",
        "    f_z=tf.layers.dense(z, n_y)\n",
        "    return f_z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4Ko5FIzCSQt",
        "colab_type": "code",
        "outputId": "5ac2bcc3-515f-40b2-af88-d91604662c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data= tf.placeholder(tf.float32, [None, n_y], name = 'y')\n",
        "\n",
        "#z posterior sampling\n",
        "def sampling_z( mu, logsigma):\n",
        "    std = tf.exp(0.5*logsigma)\n",
        "    eps = tf.random_normal(shape=[tf.shape(data)[0],\n",
        "                              n_z],\n",
        "                       mean=0.0,\n",
        "                       stddev=1.0)\n",
        "    return mu + tf.sqrt(std) * eps\n",
        "# posterior of z given y\n",
        "z_mu, z_logsigma = encoder(data)\n",
        "print(z_logsigma.shape)\n",
        "z = sampling_z(z_mu, z_logsigma)\n",
        "print(z)\n",
        "x_tilde = decoder(z)\n",
        "W = tf.exp(logW)\n",
        "lam_bda=tf.exp(loglambda)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 10)\n",
            "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM1CXFG3GPWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W=tf.cast(W,tf.float32)\n",
        "lam_bda=tf.cast(lam_bda,tf.float32)\n",
        "er=1e-8\n",
        "l_zero =  -tf.log(1+2*W*lam_bda)/2 - x_tilde*x_tilde*lam_bda/(1+2*W*lam_bda)\n",
        "print(l_zero.shape)\n",
        "l_nonzero=tf.log(1-tf.exp(-lam_bda*data*data)+er)  - tf.log(W+er)/2 - (data-x_tilde)*(data-x_tilde)/(2*W)\n",
        "l=tf.multiply(tf.cast(data<er,tf.float32),l_zero)+tf.multiply(tf.cast(data>=er,tf.float32),l_nonzero)\n",
        "Y = tf.distributions.Normal(tf.zeros_like(z_mu), tf.ones_like(z_logsigma))\n",
        "X = tf.distributions.Normal(z_mu, tf.sqrt(tf.exp(z_logsigma)))\n",
        "     \n",
        "kl_z =tf.distributions.kl_divergence(X, Y)\n",
        "print(kl_z)     \n",
        "lossv = - tf.reduce_sum(l,1) +tf.reduce_sum(kl_z,1) \n",
        "loss=(tf.reduce_mean(lossv))\n",
        "train_op = tf.train.AdamOptimizer(learn_rate).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOrOQFyrHfSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "sess=tf.Session()\n",
        "iteration=1\n",
        "sess.run(tf.global_variables_initializer())\n",
        "los_old=0\n",
        "for i in range(800):\n",
        "   for X in get_batches(expression, 100):#batch_size=100\n",
        "           \n",
        "                sess.run(train_op,{data: X})\n",
        "                iteration=iteration+1\n",
        "    \n",
        "            \n",
        "            # Print at each 5 iters\n",
        "                if (iteration % 10 == 0):\n",
        "                  los=sess.run(loss,{data: expression})\n",
        "                  print(los)\n",
        "                \n",
        "                  if abs(los-los_old)<0.05:\n",
        "                    break\n",
        "                  los_old=los\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzk3Wsre_mk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z=sess.run(z,{data: expression})\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_GJJ9Bc_5LH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "25af0c0a-22ef-4fb7-c17d-2fc60ee661d6"
      },
      "source": [
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
        "from sklearn.metrics import adjusted_rand_score as ARI\n",
        "\n",
        "labels_pred_Z = KMeans(7, n_jobs=8, n_init=100).fit_predict(Z)\n",
        "print(\"Tthe NMI and ARI is\")\n",
        "[NMI(label, labels_pred_Z), ARI(label, labels_pred_Z)]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tthe NMI and ARI is\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7540025500601544, 0.7114940572618722]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVdRaVMoS3ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGnD5yEaAJMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}